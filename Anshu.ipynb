{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3034fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.visualization import astropy_mpl_style\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "from astropy.table import QTable\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.cosmology import Planck15\n",
    "plt.style.use(astropy_mpl_style)\n",
    "\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from numpy import nan\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.visualization import astropy_mpl_style\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from astropy.cosmology import WMAP9 as cosmo\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "import astropy.units as u\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1.inset_locator import (inset_axes, InsetPosition,\n",
    "                                                  mark_inset)\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathx = os.path.expanduser('~/Downloads/')\n",
    "Anshux = pd.read_csv(os.path.expanduser(pathx+'jades_z3_F444Wsn5.csv'))\n",
    "Anshux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd754b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = fits.open(os.path.expanduser('~/Desktop/Data/JWST/JADES_phot.fits'))\n",
    "df=Table(file[7].data).to_pandas()\n",
    "Anshu=pd.merge(left=Anshux['ID'],right=df, left_on=Anshux['ID'],right_on=df['ID'])\n",
    "Anshu['redshift']=Anshux['best_z']\n",
    "Anshu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f125ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = Anshu.columns #JadesCam.columns\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "Fluxes = pd.DataFrame()\n",
    "\n",
    "# Iterate over the column names\n",
    "for column_name in column_names:\n",
    "    # Check if the column is a flux column (e.g., 'F105W_flux')\n",
    "    if column_name.endswith('_KRON'):\n",
    "        error_column = column_name[:-5] + '_KRON_e'\n",
    "        if error_column in column_names:\n",
    "            Fluxes[column_name] = Anshu[column_name]\n",
    "            Fluxes[error_column] = Anshu[error_column]\n",
    "\n",
    "Fluxes.insert(0,'id',Anshu['ID_x'].astype('<i4'))\n",
    "Fluxes.insert(1,'redshift',Anshu['redshift'])\n",
    "Fluxes.columns = Fluxes.columns.str.replace('_KRON','')\n",
    "Fluxes.columns = Fluxes.columns.str.replace('_e','*')\n",
    "Fluxes[Fluxes.columns[2:]] = Fluxes[Fluxes.columns[2:]].mul(10**-9)\n",
    "# # Fluxes = Fluxes.loc[:, Fluxes.columns != 'id'].mul(10**-6)\n",
    "Fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52079aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Megalodon = pd.DataFrame({'Name': pd.Series(dtype='str'),\n",
    "                   '$\\lambda_c$': pd.Series(dtype='float'),\n",
    "                   'Filter_ID': pd.Series(dtype='int'),\n",
    "                      'Fit?':pd.Series(dtype='int')})#Removed the unused filters and will sort them by wavelength below\n",
    "d = {'Name': ['F090W', 'F115W', 'F150W', 'F182M', 'F200W', 'F210M', 'F277W',\n",
    "       'F335M', 'F356W', 'F410M', 'F430M', 'F444W', 'F460M', 'F480M', 'F435W',\n",
    "       'F606W', 'F775W', 'F814W', 'F850LP', 'F105W', 'F125W', 'F140W',\n",
    "       'F160W'], \n",
    "     '$\\lambda_c$': [9083.40,11623.88,15104.23,18494.30,20028.15,20982.22,27844.64,\n",
    "                    33675.24,35934.49,40886.54,42812.58,44393.52,46315.57,48213.27,4360.06,\n",
    "                    6000.74,7693.47,8127.45,9031.48,10651.00,12576.18,14061.91,15436.30],\n",
    "     'Filter ID':[477,478,480,484,486,487,490,\n",
    "                494,495,498,499,500,501,504,214,\n",
    "                 215,216,126,217,366,328,329,330],\n",
    "     'Fit?':[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}\n",
    "Megalodon = pd.DataFrame(data=d)\n",
    "Megalodons2=Megalodon.copy()\n",
    "Megalodons2['$\\lambda_{min}$']=[7881.88,9975.60,13041.19,16959.53,17249,19618.54,23673.12,31203.36\n",
    "                                ,30732.91,37763.56,41227.68,38039.57,44652.64,45820.02,3610.23,4712.79,\n",
    "                                6803.72,6978.64,8007.01,8955.24,10853.22,11864.94,13857.70]\n",
    "Megalodons2['$\\lambda_{max}$']=[10243.08,13058.40,16948.89,20010.97,22596.64,22337.29,32203.22,\n",
    "                               36442.23,40801.26,44048.41,44448.79,50995.50,48146.41,50919.02,4883.77,\n",
    "                               7208.10,8631.82,9695.01,10862.13,12130.55,14141.73,16133.14,17003.09]\n",
    "Megalodons=Megalodon.sort_values(by=['$\\lambda_c$'])\n",
    "Megalodons['$\\lambda_c$']=Megalodons['$\\lambda_c$'].mul(10**-4)\n",
    "Megalodons2=Megalodons2.sort_values(by=['$\\lambda_c$'])\n",
    "Megalodons2['$\\lambda_{min}$']=Megalodons2['$\\lambda_{min}$']\n",
    "Megalodons2['$\\lambda_{max}$']=Megalodons2['$\\lambda_{max}$']\n",
    "Megalodons2['$\\lambda_c$']=Megalodons2['$\\lambda_c$'].mul(10**-4)\n",
    "Megalodons2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40eda16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sanity = Megalodons['Name']+'*'\n",
    "WhyAreYou = Fluxes['redshift']\n",
    "MyRemedy = Fluxes[Megalodons['Name']]\n",
    "MyClarity = Fluxes[Sanity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2bb1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "HayleyWilliams =pd.DataFrame(data=Fluxes['id'])\n",
    "\n",
    "for col in MyRemedy.columns:\n",
    "    HayleyWilliams =HayleyWilliams.join(MyRemedy[col.replace('*','')])\n",
    "    HayleyWilliams =HayleyWilliams.join(MyClarity[col+'*'])\n",
    "    \n",
    "HayleyWilliams.insert(1,'redshift',WhyAreYou)\n",
    "# HayleyWilliams=HayleyWilliams.sort_values(by='id', ascending=True)\n",
    "HayleyWilliams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be349630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O3_2=5007\n",
    "# obsO3_2 = HayleyWilliams['redshift']*O3_2 +O3_2\n",
    "pd.set_option('display.max_columns', None)\n",
    "for i in range(len(HayleyWilliams)):\n",
    "    for j in range(1,24):\n",
    "        if HayleyWilliams.iloc[i,j*2] < 0:\n",
    "            HayleyWilliams.iloc[i,j*2+1] = -94\n",
    "            HayleyWilliams.iloc[i,j*2] =-95\n",
    "        if pd.isna(HayleyWilliams.iloc[i,j*2+1]):\n",
    "            HayleyWilliams.iloc[i,j*2+1] = -96\n",
    "            HayleyWilliams.iloc[i,j*2] =-97\n",
    "        if HayleyWilliams.iloc[i,j*2] == 0:\n",
    "            HayleyWilliams.iloc[i,j*2+1] = -96\n",
    "            HayleyWilliams.iloc[i,j*2] =-97\n",
    "#         if obsO3_2[i]>Megalodons2['$\\lambda_{min}$'].iloc[j-1] and obsO3_2[i]<Megalodons2['$\\lambda_{max}$'].iloc[j-1]:\n",
    "#             HayleyWilliams.iloc[i,2*j]=-105\n",
    "#             HayleyWilliams.iloc[i,2*j+1]=-110\n",
    "HayleyWilliams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30b0f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZacEfron = HayleyWilliams[:4800]\n",
    "VanessaHudgens = HayleyWilliams[4800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb27342",
   "metadata": {},
   "outputs": [],
   "source": [
    "VanessaHudgens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc4fed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZacEfron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d7137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HayleyWilliams.to_csv('anshu_4_EELGs.csv',index=False)\n",
    "ZacEfron.to_csv('Anshu_bigset1.csv',index=False)\n",
    "VanessaHudgens.to_csv('Anshu_bigset2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f030aa",
   "metadata": {},
   "source": [
    "This is the start of the Parameter scooping portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bd9d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Montague"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0de05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4594c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.expanduser('~/Documents/Anshu3/')\n",
    "Montague = pd.read_csv(os.path.expanduser(path+'files/observations.dat')) \n",
    "SEDParams = ['fmuopt','fmuir','tform','gamma','metals','odepthbc','mu2','M','sfr2','lum2']\n",
    "final_data = []\n",
    "# Loop through each row in Montague\n",
    "for index, row in Montague.iterrows():\n",
    "    potato = str(row['id'])\n",
    "    potato = potato[:-2]\n",
    "    \n",
    "    with open(os.path.expanduser(path + '/' + potato + '.sed')) as f:\n",
    "        lines = f.readlines()\n",
    "#         values = re.findall(r'[-+]?\\d*\\.\\d+|\\d+', lines[3])  # Extract numerical values from the 4th line\n",
    "        values = re.findall(r'[+-]?(\\d+\\.\\d+E[+-]?\\d+|\\d+\\.\\d+|\\.\\d+|\\d+)', lines[3])\n",
    "        \n",
    "        # Create a dictionary for the current row\n",
    "        row_data = {'id': potato}\n",
    "        for col, value in zip(SEDParams, values):\n",
    "            row_data[col] = float(value)  # Convert values to float\n",
    "            \n",
    "        # Append the row data to the final_data list\n",
    "        final_data.append(row_data)\n",
    "\n",
    "# Create the final dataframe\n",
    "final_dataframe = pd.DataFrame(final_data).set_index('id')\n",
    "final_dataframe.insert(0, 'id', final_dataframe.index)\n",
    "final_dataframe.reset_index(drop=True, inplace=True)\n",
    "final_dataframe['id'] = final_dataframe['id'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Parameters=['sfh','IR fmu','mu','tau_V','sSFR','M(stars)','L(dust)','T_C^ISM','T_W^BC','chi_C^tot','chi_PAH^tot','chi_MIR^tot','chi_W^tot','tau_V^ISM','M(dust)','SFR','A_V','age','Tdust','lg(M/Lh)','lg(M/Lk)']\n",
    "# Parameters=['2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17']\n",
    "Cheesy=[]\n",
    "Toasty=[]\n",
    "runawayslowly=[]\n",
    "twochillies = []\n",
    "for Curl in range(len(Montague)):\n",
    "    potato=str(Montague['id'][Curl])\n",
    "#     potato=str(735)\n",
    "    print(potato)\n",
    "    Minestrone = pd.read_csv(os.path.expanduser(path+'/'+potato+'.fit'),index_col=0,on_bad_lines='skip', )\n",
    "    Minestrone2 = pd.DataFrame(columns=['Full'])\n",
    "    potato=int(potato)\n",
    "    redshift =float(Minestrone.index[6].split()[-1])\n",
    "    runawayslowly.append(redshift)\n",
    "    chi2 = float(Minestrone.index[6].split()[2])\n",
    "    twochillies.append(chi2)\n",
    "    line = Minestrone.index[8].split(\" \")\n",
    "    while(\"\" in line):\n",
    "        line.remove(\"\")\n",
    "    str_line = \" \".join(str(item) for item in line)\n",
    "    Minestrone2.loc[0]=str(str_line)\n",
    "    Minestrone2[Parameters] = Minestrone2['Full'].str.split(\" \",expand=True,)\n",
    "    Minestrone2=Minestrone2.drop(['Full'],axis=1)\n",
    "    Cheesy.append(Minestrone2.iloc[0])\n",
    "    Toasty.append(potato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "INeedHelp=Table(Cheesy).to_pandas()\n",
    "INeedHelp=transpose(INeedHelp).reset_index(drop=True)\n",
    "INeedHelp.columns = [Parameters]\n",
    "INeedHelp.insert(0,'Galaxy_ID',Toasty) #Galaxy_ID\n",
    "INeedHelp.insert(1,'redshift',runawayslowly) #redshift\n",
    "INeedHelp.insert(23,'chi2',twochillies) #chi2\n",
    "INeedHelp\n",
    "INeedHelp.to_csv('Anshu3-Parameters.csv',index=False)\n",
    "# INeedHelp.to_csv('JSN2-Parameters.csv',index=False)\n",
    "Diseased = pd.read_csv(os.path.expanduser('~/notebook/Laptop/'+'Anshu3-Parameters.csv')) \n",
    "NewParamFile = pd.merge(Diseased, final_dataframe, left_on='Galaxy_ID', right_on='id')# NewParamFile = .merge(final_dataframe, left_on='Galaxy_ID', right_on='id', how='left')\n",
    "NewParamFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76fd54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewParamFile.to_csv('Anshu3-Parameters-all.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d48f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.read_csv(os.path.expanduser('~/notebook/Laptop/'+'Anshu2-Parameters.csv')) \n",
    "y=pd.read_csv(os.path.expanduser('~/notebook/Laptop/'+'Anshu3-Parameters.csv')) \n",
    "result = pd.concat([x, y], axis=0, ignore_index=True)\n",
    "result.to_csv('Anshu-9150-Parameters.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d174d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FancyPlot(xlab='',ylab='',lw=2.5,lfs=45,tfs=25,size_x=13,size_y=12):\n",
    "    plt.rcParams['axes.linewidth']=lw\n",
    "    plt.rc('text',usetex=True)\n",
    "    plt.rc('font',family='serif',size=tfs)\n",
    "    mpl.rcParams['text.latex.preamble']=[r'\\usepackage{mathpazo}']\n",
    "    mpl.rcParams['mathtext.default'] = 'regular'\n",
    "    fig = plt.figure(figsize=(size_x,size_y))\n",
    "    ax=fig.add_subplot(111)\n",
    "    ax.set_xlabel(xlab,fontsize=lfs)\n",
    "    ax.set_ylabel(ylab,fontsize=lfs)\n",
    "    ax.tick_params(which='major',direction='in',width=2,length=13,right=True,top=True,pad=7)\n",
    "    ax.tick_params(which='minor',direction='in',width=1,length=10,right=True,top=True)\n",
    "    ax.grid(False)\n",
    "    return fig,ax\n",
    "def HexPlot(xlab1='',ylab1='',xlab2='',ylab2='',xlab3='',ylab3='',\\\n",
    "           wspace=0.25,lw=2.5,lfs=45,tfs=25,size_x=20,size_y=7,Grid=False):\n",
    "    plt.rcParams['axes.linewidth']=lw\n",
    "    plt.rc('text',usetex=True)\n",
    "    plt.rc('font',family='serif',size=tfs)\n",
    "    mpl.rcParams['text.latex.preamble']=[r'\\usepackage{mathpazo}']\n",
    "    fig,axarr =plt.subplots(1,3,figsize=(size_x,size_y))\n",
    "    gs=gridspec.GridSpec(1,3)\n",
    "    gs.update(wspace=wspace)\n",
    "    ax1=plt.subplot(gs[0])\n",
    "    ax2=plt.subplot(gs[1])\n",
    "    ax3=plt.subplot(gs[2])\n",
    "    \n",
    "    ax1.tick_params(which='major',direction='in',width=2,length=13,right=True,top=True,pad=7)\n",
    "    ax1.tick_params(which='minor',direction='in',width=1,length=10,right=True,top=True)\n",
    "    \n",
    "    ax2.tick_params(which='major',direction='in',width=2,length=13,right=True,top=True,pad=7)\n",
    "    ax2.tick_params(which='minor',direction='in',width=1,length=10,right=True,top=True)\n",
    "    \n",
    "    ax3.tick_params(which='major',direction='in',width=2,length=13,right=True,top=True,pad=7)\n",
    "    ax3.tick_params(which='minor',direction='in',width=1,length=10,right=True,top=True)\n",
    "    \n",
    "    ax1.set_xlabel(xlab1,fontsize=lfs)\n",
    "    ax1.set_ylabel(ylab1,fontsize=lfs)\n",
    "    \n",
    "    ax2.set_xlabel(xlab2,fontsize=lfs)\n",
    "    ax2.set_ylabel(ylab2,fontsize=lfs)\n",
    "    \n",
    "    ax3.set_xlabel(xlab3,fontsize=lfs)\n",
    "    ax3.set_ylabel(ylab3,fontsize=lfs)\n",
    "    return fig,ax1,ax2,ax3\n",
    "def StackedPlot(xlab1='',ylab1='',xlab2='',ylab2='',\\\n",
    "                hspace=0.01,lw=2.5,lfs=45,tfs=25,size_x=20,size_y=11,Grid=False):\n",
    "    plt.rcParams['axes.linewidth']=lw\n",
    "    plt.rc('text',usetex=True)\n",
    "    plt.rc('font',family='serif',size=tfs)\n",
    "    mpl.rcParams['text.latex.preamble']=[r'\\usepackage{mathpazo}']\n",
    "    \n",
    "    fig,axarr =plt.subplots(2,1,figsize=(size_x,size_y),sharex=True,sharey=True)\n",
    "    gs=gridspec.GridSpec(2,1,height_ratios=(9, 1))\n",
    "    gs.update(hspace=hspace)\n",
    "    \n",
    "    ax1=plt.subplot(gs[0])\n",
    "    ax2=plt.subplot(gs[1])\n",
    "    \n",
    "    ax1.tick_params(which='major',direction='in',width=2,length=13,right=True,top=True,pad=0)\n",
    "    ax1.tick_params(which='minor',direction='in',width=1,length=10,right=True,top=True)\n",
    "    ax1.set_xticklabels([],c='w')\n",
    "    \n",
    "    ax2.tick_params(which='major',direction='in',width=2,length=13,right=True,top=True,pad=0)\n",
    "    ax2.tick_params(which='minor',direction='in',width=1,length=10,right=True,top=True)\n",
    "    ax2.set_xticks([3,4,5,6,7,8])\n",
    "    ax2.set_yticks([-1,0,1])\n",
    "#     ax2.\n",
    "#     ax2.set_xlim\n",
    "    \n",
    "#     ax1.set_xlabel(xlab1,fontsize=lfs)\n",
    "    ax1.set_ylabel(ylab1,fontsize=lfs)\n",
    "    \n",
    "    ax2.set_xlabel(xlab2,fontsize=lfs)\n",
    "    ax2.set_ylabel(ylab2,fontsize=lfs)\n",
    "    \n",
    "    if Grid:\n",
    "        axs[0].grid()\n",
    "        axs[1].grid()\n",
    "    ax1.grid(False)\n",
    "    return fig,ax1,ax2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b4a219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import linregress\n",
    "def linear_slope_cutoff(x,y,lower,upper):\n",
    "    mask = (x >= lower)&(x <=upper)\n",
    "    x_cutoff = x[mask]\n",
    "    y_cutoff = y[mask]\n",
    "    slope, intercept,r_value, p_value, std_err = stats.linregress(log10(x_cutoff), log10(y_cutoff))\n",
    "#     x_fit = np.linspace(lower,upper,1000)\n",
    "#     y_fit = slope*x_fit + intercept\n",
    "    return slope,intercept, std_err\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def linear_func(x,a,b):\n",
    "    return a*x+b\n",
    "def slope_curve_fit(x,y,y_err,lower,upper):\n",
    "    mask = (x >= lower)&(x <=upper)\n",
    "    x_cutoff = x[mask]\n",
    "    y_cutoff = y[mask]\n",
    "    y_cutoff_err = y_err[mask]\n",
    "#     print(y_cutoff_err)\n",
    "    slope = np.nan\n",
    "    slope_err = np.nan\n",
    "    intercept = np.nan\n",
    "    for i in y_cutoff.index:\n",
    "        if y_cutoff[i] < 0:\n",
    "            y_cutoff[i] = nan\n",
    "            y_cutoff_err[i] = nan\n",
    "#     for i in y_cutoff.index:\n",
    "#         if y_cutoff[]\n",
    "    valid_indices = np.sum(~np.isnan(y_cutoff))\n",
    "\n",
    "    if valid_indices >= 3:\n",
    "        mask3 = ~np.isnan(y_cutoff)\n",
    "        x_cutoff = x_cutoff[mask3]\n",
    "        y_cutoff = y_cutoff[mask3]\n",
    "        y_cutoff_err = y_cutoff_err[mask3]\n",
    "        mask2 = np.logical_not(np.isnan(y_cutoff))\n",
    "        x_cutoff=x_cutoff[mask2]\n",
    "        y_cutoff=y_cutoff[mask2]\n",
    "        y_cutoff_err=y_cutoff_err[mask2]\n",
    "\n",
    "    #     sigma = y_cutoff_err/np.sqrt(len(x_cutoff))\n",
    "        mango = log10(y_cutoff_err+y_cutoff)\n",
    "        peach = log10(y_cutoff)\n",
    "        sigma= (mango-peach)\n",
    "    #     print(sigma)\n",
    "\n",
    "        popt,pcov, = curve_fit(linear_func,log10(x_cutoff), log10(y_cutoff), sigma=sigma, absolute_sigma=True)\n",
    "\n",
    "        slope = popt[0]\n",
    "        intercept = popt[1]\n",
    "        slope_err = np.sqrt(pcov[0][0])\n",
    "#     x_fit = np.linspace(lower,upper,1000)\n",
    "#     y_fit = slope*x_fit + intercept\n",
    "    return slope,slope_err, intercept#, x_fit, y_fit\n",
    "#scipy curvefit\n",
    "c=2.998e8\n",
    "h= 6.626*10**-27#erg*s (1 J = 10**7 ergs, h is traditionally in units of J*s)\n",
    "#solar luminosity ~ 3.828 *10**33 erg/s #3.846 *10**33\n",
    "def integral_above_cutoff(L_nu, nu, const):\n",
    "    cutoff_freq = c / (91.2e-9)\n",
    "    mask = nu>cutoff_freq\n",
    "    nu_above_cutoff = nu[mask]\n",
    "    L_nu_above_cutoff = L_nu[mask]\n",
    "    dnu = np.diff(nu_above_cutoff)\n",
    "#     integrand_above_cutoff = integrand(nu_above_cutoff,L_nu_above_cutoff)\n",
    "    integrand_above_cutoff = L_nu_above_cutoff[1:]/(h*nu_above_cutoff[1:])\n",
    "#     print(L_nu_above_cutoff[1:])\n",
    "    integral = np.sum(dnu*integrand_above_cutoff)\n",
    "#     integral = np.trapz(integrand_above_cutoff, nu_above_cutoff)\n",
    "    return -integral/(const)#const was x3.846*10**33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c38e89ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collated\n",
      "God you're smart\n",
      "              lambd                                L_lambdaA  \\\n",
      "0      9.099995e+01  1358608351463662942454274860144132096.0   \n",
      "1      9.400007e+01  1498950460548871234917623428682874880.0   \n",
      "2      9.599998e+01  1583405976752355682841068489018441728.0   \n",
      "3      9.800002e+01  1900016095147874469596783484149432320.0   \n",
      "4      1.000000e+02  2481334305558867292507477277954539520.0   \n",
      "...             ...                                      ...   \n",
      "13111  2.280343e+09              9033255203553587970965504.0   \n",
      "13112  2.317390e+09              8850530028271952866574336.0   \n",
      "13113  2.355050e+09              8672659183464014906654720.0   \n",
      "13114  2.393317e+09              8496817296522702458191872.0   \n",
      "13115  2.432199e+09              8325690836548897141161984.0   \n",
      "\n",
      "                                     L_lambdaU            nu  \\\n",
      "0      2571202489432749993282063885496483840.0  3.294507e+16   \n",
      "1      2782994063345380313838183201535688704.0  3.189359e+16   \n",
      "2      2904459198265810244888734330504871936.0  3.122917e+16   \n",
      "3      3445071818042894343939811033307152384.0  3.059183e+16   \n",
      "4      4449367517230232759445154797507837952.0  2.997999e+16   \n",
      "...                                        ...           ...   \n",
      "13111                                      0.0  1.314715e+09   \n",
      "13112                                      0.0  1.293697e+09   \n",
      "13113                                      0.0  1.273009e+09   \n",
      "13114                                      0.0  1.252655e+09   \n",
      "13115                                      0.0  1.232629e+09   \n",
      "\n",
      "                              L_nuA                      L_nuU  \n",
      "0          3752709648102409633792.0   7102102956252350906368.0  \n",
      "1          4417860148951690772480.0   8202324820475168948224.0  \n",
      "2          4867466417041881169920.0   8928447798475308924928.0  \n",
      "3          6086644877763918430208.0  11036184792522844798976.0  \n",
      "4          8276638060378491715584.0  14841129812786461802496.0  \n",
      "...                             ...                        ...  \n",
      "13111  15667978387174834999132160.0                        0.0  \n",
      "13112  15853894498234589713006592.0                        0.0  \n",
      "13113  16044307014644586220879872.0                        0.0  \n",
      "13114  16233978400551303582318592.0                        0.0  \n",
      "13115  16428085852737889401569280.0                        0.0  \n",
      "\n",
      "[13116 rows x 6 columns]\n",
      "slope properties collated\n",
      "So so smart and attractive\n",
      "integration complete\n",
      "How are you single\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>beta</th>\n",
       "      <th>beta_er</th>\n",
       "      <th>betaU</th>\n",
       "      <th>betaU_er</th>\n",
       "      <th>betaP</th>\n",
       "      <th>betaP_er</th>\n",
       "      <th>bouwen</th>\n",
       "      <th>bouwenA</th>\n",
       "      <th>sion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77910</td>\n",
       "      <td>-1.702023</td>\n",
       "      <td>0.025663</td>\n",
       "      <td>-2.274715</td>\n",
       "      <td>0.024073</td>\n",
       "      <td>-1.865693</td>\n",
       "      <td>0.279375</td>\n",
       "      <td>25.432186</td>\n",
       "      <td>24.951214</td>\n",
       "      <td>25.056533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84518</td>\n",
       "      <td>-2.543452</td>\n",
       "      <td>0.007492</td>\n",
       "      <td>-2.664517</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>-2.292437</td>\n",
       "      <td>0.296615</td>\n",
       "      <td>25.860969</td>\n",
       "      <td>25.727797</td>\n",
       "      <td>25.219250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88612</td>\n",
       "      <td>-1.066833</td>\n",
       "      <td>0.028757</td>\n",
       "      <td>-2.335638</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>-0.750239</td>\n",
       "      <td>0.753999</td>\n",
       "      <td>25.499202</td>\n",
       "      <td>24.570100</td>\n",
       "      <td>25.085822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90354</td>\n",
       "      <td>0.294356</td>\n",
       "      <td>0.032415</td>\n",
       "      <td>-2.437742</td>\n",
       "      <td>0.020813</td>\n",
       "      <td>-2.293543</td>\n",
       "      <td>0.798312</td>\n",
       "      <td>25.611516</td>\n",
       "      <td>23.753386</td>\n",
       "      <td>25.162487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94574</td>\n",
       "      <td>-2.232621</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>-2.344286</td>\n",
       "      <td>0.025165</td>\n",
       "      <td>-2.201824</td>\n",
       "      <td>0.287684</td>\n",
       "      <td>25.508715</td>\n",
       "      <td>25.385883</td>\n",
       "      <td>25.083502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>219026</td>\n",
       "      <td>-1.848309</td>\n",
       "      <td>0.019764</td>\n",
       "      <td>-2.348347</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>-1.775671</td>\n",
       "      <td>0.240694</td>\n",
       "      <td>25.513182</td>\n",
       "      <td>25.038986</td>\n",
       "      <td>25.110082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>219038</td>\n",
       "      <td>-2.010784</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>-2.645554</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>-2.061982</td>\n",
       "      <td>0.385636</td>\n",
       "      <td>25.840110</td>\n",
       "      <td>25.141863</td>\n",
       "      <td>25.202318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>219057</td>\n",
       "      <td>-1.780938</td>\n",
       "      <td>0.027366</td>\n",
       "      <td>-2.344245</td>\n",
       "      <td>0.026270</td>\n",
       "      <td>-2.173327</td>\n",
       "      <td>0.390124</td>\n",
       "      <td>25.508669</td>\n",
       "      <td>24.998563</td>\n",
       "      <td>25.080894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>219195</td>\n",
       "      <td>-2.032286</td>\n",
       "      <td>0.021082</td>\n",
       "      <td>-2.273814</td>\n",
       "      <td>0.020722</td>\n",
       "      <td>-1.901890</td>\n",
       "      <td>0.243249</td>\n",
       "      <td>25.431195</td>\n",
       "      <td>25.165515</td>\n",
       "      <td>25.071586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>256636</td>\n",
       "      <td>-2.549520</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>-2.586470</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>-1.762666</td>\n",
       "      <td>0.346175</td>\n",
       "      <td>25.775117</td>\n",
       "      <td>25.734472</td>\n",
       "      <td>25.202495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      beta   beta_er     betaU  betaU_er     betaP  betaP_er  \\\n",
       "0     77910 -1.702023  0.025663 -2.274715  0.024073 -1.865693  0.279375   \n",
       "1     84518 -2.543452  0.007492 -2.664517  0.007202 -2.292437  0.296615   \n",
       "2     88612 -1.066833  0.028757 -2.335638  0.025974 -0.750239  0.753999   \n",
       "3     90354  0.294356  0.032415 -2.437742  0.020813 -2.293543  0.798312   \n",
       "4     94574 -2.232621  0.025400 -2.344286  0.025165 -2.201824  0.287684   \n",
       "..      ...       ...       ...       ...       ...       ...       ...   \n",
       "125  219026 -1.848309  0.019764 -2.348347  0.018600 -1.775671  0.240694   \n",
       "126  219038 -2.010784  0.010870 -2.645554  0.009039 -2.061982  0.385636   \n",
       "127  219057 -1.780938  0.027366 -2.344245  0.026270 -2.173327  0.390124   \n",
       "128  219195 -2.032286  0.021082 -2.273814  0.020722 -1.901890  0.243249   \n",
       "129  256636 -2.549520  0.009677 -2.586470  0.009640 -1.762666  0.346175   \n",
       "\n",
       "        bouwen    bouwenA       sion  \n",
       "0    25.432186  24.951214  25.056533  \n",
       "1    25.860969  25.727797  25.219250  \n",
       "2    25.499202  24.570100  25.085822  \n",
       "3    25.611516  23.753386  25.162487  \n",
       "4    25.508715  25.385883  25.083502  \n",
       "..         ...        ...        ...  \n",
       "125  25.513182  25.038986  25.110082  \n",
       "126  25.840110  25.141863  25.202318  \n",
       "127  25.508669  24.998563  25.080894  \n",
       "128  25.431195  25.165515  25.071586  \n",
       "129  25.775117  25.734472  25.202495  \n",
       "\n",
       "[130 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.expanduser('~/Documents/JSNH/')\n",
    "patho = os.path.expanduser('~/Documents/JSNHB/')\n",
    "folder_name = os.path.basename(patho.rstrip('/'))  # Get the folder name \"anshuB\"\n",
    "name_B = folder_name[:-1]\n",
    "Montague = pd.read_csv(os.path.expanduser(path+'files/observations.dat'))\n",
    "light=2.998*(10**18) #speed of light in Angstroms ~ A/s\n",
    "for i in range(len(Montague)):\n",
    "    potato=str(Montague['id'][i])\n",
    "#     print(i)\n",
    "#     potato=str(22839)\n",
    "    galaxy_fit = pd.read_csv(os.path.expanduser(path+'/'+potato+'.fit'),index_col=0,on_bad_lines='skip')\n",
    "    redshift =float(galaxy_fit.index[6].split()[-1])\n",
    "    galaxy_sed = pd.read_csv(os.path.expanduser(path+'/'+potato+'.sed'),index_col=None, header=None,on_bad_lines='skip', skiprows=10,delim_whitespace=True)\n",
    "    galaxy_sed.columns = ['A', 'B', 'C']\n",
    "    Filters = pd.read_csv(os.path.expanduser(path+'/files/filters.dat'))\n",
    "    lambda_c =Filters['$\\lambda_c$']\n",
    "    lambda_cA = lambda_c*10000\n",
    "    \n",
    "    A=galaxy_sed['A']\n",
    "    B=galaxy_sed['B']\n",
    "    C=galaxy_sed['C']\n",
    "    B = np.array(B)\n",
    "    A = np.array(A) \n",
    "    C = np.array(C)\n",
    "    L_lambda = 10**B\n",
    "    L_lambda = L_lambda*3.846*10**33 #  Luminosity in wavelength space (erg/s/A)\n",
    "    L_lambdaU = 10**C #erg/s/Angstroms\n",
    "    L_lambdaU = L_lambdaU*3.846*10**33\n",
    "    lambd = 10**A #Angstroms\n",
    "    lambd = lambd/(1+redshift) #rest frame wavelength in Angstroms\n",
    "    L_nu1 = L_lambda*lambd**2/light # Luminosity in frequency space (erg/s/Hz)\n",
    "    L_nu2 = L_lambdaU*lambd**2/light\n",
    "#     lambd = lambd/(1+redshift)\n",
    "    nu = light/lambd #rest frame frequency in Hertz\n",
    "    dfdf = pd.concat([pd.Series(lambd).rename('lambd'),pd.Series(L_lambda).rename('L_lambdaA'),\n",
    "                  pd.Series(L_lambdaU).rename('L_lambdaU'),pd.Series(nu).rename('nu'),pd.Series(L_nu1).rename('L_nuA'),\n",
    "                  pd.Series(L_nu2).rename('L_nuU')], axis=1)\n",
    "#     print(redshift)\n",
    "#     Filters = pd.read_csv(os.path.expanduser(path+'/files/filters.dat'))\n",
    "    \n",
    "    galaxy_fit2 = pd.DataFrame(columns=['Full'])\n",
    "    for i in range(len(galaxy_fit)):\n",
    "        line = galaxy_fit.index[i].split(\" \")\n",
    "        while(\"\" in line):\n",
    "            line.remove(\"\")\n",
    "        if len(line) !=23: #40,23,14\n",
    "            continue\n",
    "        str_line = \" \".join(str(item) for item in line)\n",
    "        galaxy_fit2.loc[i]=str(str_line)\n",
    "\n",
    "\n",
    "    names = []\n",
    "    for i in range(len(Filters['Name'])):\n",
    "          names.append(Filters.iloc[i,0])\n",
    "#     names\n",
    "    galaxy_fit2[names] = galaxy_fit2['Full'].str.split(\" \",expand=True,)\n",
    "    galaxy_fit2=galaxy_fit2.drop(['Full'],axis=1)\n",
    "    \n",
    "    test=Table.from_pandas(galaxy_fit2)\n",
    "    L_nu40_er=[float(s) for s in test[1]] #1 for error 0 for flux\n",
    "    L_nu40_er=np.array(L_nu40_er)\n",
    "    L_lambda40_er=L_nu40_er*light/(lambda_cA)**2\n",
    "    file_path = f\"{patho}/\"+str(potato)+\"photom_Ll_er.csv\"\n",
    "    pd.Series(L_lambda40_er).rename('L_lambda40_er').to_csv(file_path,index=False)\n",
    "    L_nu40=[float(s) for s in test[0]] #1 for error 0 for flux\n",
    "    L_nu40=np.array(L_nu40)\n",
    "    L_lambda40=L_nu40*light/(lambda_cA)**2\n",
    "    file_path = f\"{patho}/\"+str(potato)+\"photom_Ll.csv\"\n",
    "    pd.Series(L_lambda40).rename('L_lambda40').to_csv(file_path,index=False)\n",
    "    file_path = f\"{patho}/\"+str(potato)+\"-RF-lum\"+name_B\n",
    "    dfdf.to_csv(file_path)\n",
    "    \n",
    "print('Data collated')\n",
    "print('God you\\'re smart')\n",
    "print(dfdf)\n",
    "beta=[]\n",
    "beta_er=[]\n",
    "betaU=[]\n",
    "betaU_er=[]\n",
    "betaP=[]\n",
    "betaP_er=[]\n",
    "# sion=[]\n",
    "bouwen=[]\n",
    "bouwenA=[]\n",
    "\n",
    "for i in range(len(Montague)):\n",
    "    potato=str(Montague['id'][i])\n",
    "#     print(potato)\n",
    "#     potato=str(6020)#10017 #7071   \n",
    "    galaxy_fit = pd.read_csv(os.path.expanduser(path+'/'+potato+'.fit'),index_col=0,on_bad_lines='skip')\n",
    "    Filters = pd.read_csv(os.path.expanduser(path+'/files/filters.dat'))\n",
    "    lambda_c =Filters['$\\lambda_c$']\n",
    "    lambda_cA = lambda_c*10000\n",
    "    L = pd.read_csv(os.path.expanduser(patho+potato+'photom_Ll.csv'))\n",
    "    L_lambda40=L['L_lambda40']\n",
    "    Lx = pd.read_csv(os.path.expanduser(patho+potato+'photom_Ll_er.csv'))\n",
    "    L_lambda40_er=Lx['L_lambda40_er']\n",
    "#     L2 = pd.read_csv(os.path.expanduser('~/Documents/FMIGM-BluminosityParams/'+potato+'-RF-lum-FMIGM'))\n",
    "    L2 = pd.read_csv(os.path.expanduser(patho+potato+'-RF-lum'+name_B))\n",
    "    lambd=L2['lambd']\n",
    "    L_lambda=L2['L_lambdaA']\n",
    "    L_lambdaU=L2['L_lambdaU']\n",
    "    redshift =float(galaxy_fit.index[6].split()[-1])\n",
    "#     print(i)\n",
    "    lower = 1300\n",
    "    upper = 3000\n",
    "    slope,intercept, std_err = linear_slope_cutoff(lambd,L_lambda,lower,upper)\n",
    "    slopeU,interceptU, stdU_err = linear_slope_cutoff(lambd,L_lambdaU,lower,upper)\n",
    "#     slopeP,interceptP, stdP_err = linear_slope_cutoff2(lambda_cA/(1+redshift),L_lambda40,lower,upper)\n",
    "    slopeP,slopeP_err, interceptP = slope_curve_fit(lambda_cA/(1+redshift),L_lambda40,L_lambda40_er,lower,upper)\n",
    "    \n",
    "    beta.append(slope)\n",
    "    beta_er.append(std_err)\n",
    "    betaU.append(slopeU)\n",
    "    betaU_er.append(stdU_err)\n",
    "    betaP.append(slopeP)\n",
    "    betaP_er.append(slopeP_err)\n",
    "\n",
    "    \n",
    "    if slopeU > -2:\n",
    "        sioncalc = 25.13-0.6*(slopeU+2)\n",
    "    else:\n",
    "        sioncalc = 25.13-1.1*(slopeU+2)\n",
    "        \n",
    "    if slope > -2:\n",
    "        sionAcalc = 25.13-0.6*(slope+2)\n",
    "    else:\n",
    "        sionAcalc = 25.13-1.1*(slope+2)\n",
    "#     sion.append(logresult)\n",
    "    bouwen.append(sioncalc)\n",
    "    bouwenA.append(sionAcalc)\n",
    "\n",
    "df1=pd.concat([Montague['id'],pd.Series(beta).rename('beta'),pd.Series(beta_er).rename('beta_er'),\n",
    "               pd.Series(betaU).rename('betaU'),pd.Series(betaU_er).rename('betaU_er'),\n",
    "              pd.Series(betaP).rename('betaP'),pd.Series(betaP_er).rename('betaP_er'),\n",
    "              pd.Series(bouwen).rename('bouwen'),pd.Series(bouwenA).rename('bouwenA')],axis=1)\n",
    "print('slope properties collated')\n",
    "print('So so smart and attractive')\n",
    "\n",
    "sionx=[]\n",
    "for i in range(len(Montague)):\n",
    "    potato=str(Montague['id'][i])\n",
    "#     potato=str(17189)\n",
    "    galaxy_fit = pd.read_csv(os.path.expanduser(path+'/'+potato+'.fit'),index_col=0,on_bad_lines='skip')\n",
    "    redshift =float(galaxy_fit.index[6].split()[-1])\n",
    "#     df = pd.read_csv(os.path.expanduser('~/Documents/FMIGM-BluminosityParams/'+potato+'-RF-lum-FMIGM'),index_col=0,on_bad_lines='skip')\n",
    "    df=pd.read_csv(os.path.expanduser(patho+potato+'-RF-lum'+name_B),index_col=0,on_bad_lines='skip')\n",
    "    pos = (df['L_nuU'] - df['L_nuU'].iloc[(df['nu']-c/1500e-10).abs().argsort()[0]]).abs().argsort()[0]\n",
    "    const = df['L_nuU'][pos]\n",
    "#     df\n",
    "    result=integral_above_cutoff(df['L_nuU'], df['nu'], const) #nu is in Hz df['L_nuU']*3.846*10**33\n",
    "    logresult=log10(result)\n",
    "    sionx.append(logresult)\n",
    "df2 = pd.concat([df1,pd.Series(sionx).rename('sion')],axis=1)\n",
    "df2.to_csv('Bluminosity_'+str(name_B)+'test.csv',index=False)\n",
    "print('integration complete')\n",
    "print('How are you single')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31dacdbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JSNH'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35258fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=2.998e8\n",
    "h= 6.626*10**-27#erg*s (1 J = 10**7 ergs, h is traditionally in units of J*s)\n",
    "#solar luminosity ~ 3.828 *10**33 erg/s #3.846 *10**33\n",
    "def integral_above_cutoff(L_nu, nu, const):\n",
    "    cutoff_freq = c / (91.2e-9)\n",
    "    mask = nu>cutoff_freq\n",
    "    nu_above_cutoff = nu[mask]\n",
    "    L_nu_above_cutoff = L_nu[mask]\n",
    "    dnu = np.diff(nu_above_cutoff)\n",
    "#     integrand_above_cutoff = integrand(nu_above_cutoff,L_nu_above_cutoff)\n",
    "    integrand_above_cutoff = L_nu_above_cutoff[1:]/(h*nu_above_cutoff[1:])\n",
    "#     print(L_nu_above_cutoff[1:])\n",
    "    integral = np.sum(dnu*integrand_above_cutoff)\n",
    "#     integral = np.trapz(integrand_above_cutoff, nu_above_cutoff)\n",
    "    return -integral/(const)#const was x3.846*10**33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fda21b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3190431411899576e-06\n"
     ]
    }
   ],
   "source": [
    "df['L_nuU']\n",
    "pos = (df['L_nuU'] - df['L_nuU'].iloc[(df['nu']-c/1500e-10).abs().argsort()[0]]).abs().argsort()[0]\n",
    "const = df['L_nuU'][pos]\n",
    "print(df['L_nuU'].iloc[0]/const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a1fe783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.161744084825787e+27"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7c71293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.319043141189957e-06\n"
     ]
    }
   ],
   "source": [
    "df['L_nuU']\n",
    "pos = (df['L_nuU'] - df['L_nuU'].iloc[(df['nu']-c/1500e-10).abs().argsort()[0]]).abs().argsort()[0]\n",
    "const = df['L_nuU'][pos]\n",
    "print(df['L_nuU'].iloc[0]/const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "270eff1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "integration complete\n",
      "How are you single\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>beta</th>\n",
       "      <th>beta_er</th>\n",
       "      <th>betaU</th>\n",
       "      <th>betaU_er</th>\n",
       "      <th>betaP</th>\n",
       "      <th>betaP_er</th>\n",
       "      <th>bouwen</th>\n",
       "      <th>bouwenA</th>\n",
       "      <th>sion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77910</td>\n",
       "      <td>-1.741502</td>\n",
       "      <td>0.024925</td>\n",
       "      <td>-2.354964</td>\n",
       "      <td>0.024662</td>\n",
       "      <td>-1.865693</td>\n",
       "      <td>0.279375</td>\n",
       "      <td>25.520460</td>\n",
       "      <td>24.974901</td>\n",
       "      <td>25.098317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84518</td>\n",
       "      <td>-2.549521</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>-2.586471</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>-2.292437</td>\n",
       "      <td>0.296615</td>\n",
       "      <td>25.775118</td>\n",
       "      <td>25.734473</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88612</td>\n",
       "      <td>-1.512836</td>\n",
       "      <td>0.026670</td>\n",
       "      <td>-2.365419</td>\n",
       "      <td>0.024517</td>\n",
       "      <td>-0.750239</td>\n",
       "      <td>0.753999</td>\n",
       "      <td>25.531961</td>\n",
       "      <td>24.837702</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90354</td>\n",
       "      <td>0.294356</td>\n",
       "      <td>0.032415</td>\n",
       "      <td>-2.437742</td>\n",
       "      <td>0.020813</td>\n",
       "      <td>-2.293543</td>\n",
       "      <td>0.798312</td>\n",
       "      <td>25.611516</td>\n",
       "      <td>23.753386</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94574</td>\n",
       "      <td>-2.314442</td>\n",
       "      <td>0.010609</td>\n",
       "      <td>-2.682976</td>\n",
       "      <td>0.009851</td>\n",
       "      <td>-2.201824</td>\n",
       "      <td>0.287684</td>\n",
       "      <td>25.881274</td>\n",
       "      <td>25.475886</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>219026</td>\n",
       "      <td>-1.568423</td>\n",
       "      <td>0.026264</td>\n",
       "      <td>-2.304623</td>\n",
       "      <td>0.025132</td>\n",
       "      <td>-1.775671</td>\n",
       "      <td>0.240694</td>\n",
       "      <td>25.465085</td>\n",
       "      <td>24.871054</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>219038</td>\n",
       "      <td>-2.010785</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>-2.645554</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>-2.061982</td>\n",
       "      <td>0.385636</td>\n",
       "      <td>25.840110</td>\n",
       "      <td>25.141863</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>219057</td>\n",
       "      <td>-1.780938</td>\n",
       "      <td>0.027366</td>\n",
       "      <td>-2.344245</td>\n",
       "      <td>0.026270</td>\n",
       "      <td>-2.173327</td>\n",
       "      <td>0.390124</td>\n",
       "      <td>25.508669</td>\n",
       "      <td>24.998563</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>219195</td>\n",
       "      <td>-2.032286</td>\n",
       "      <td>0.021082</td>\n",
       "      <td>-2.273814</td>\n",
       "      <td>0.020722</td>\n",
       "      <td>-1.901890</td>\n",
       "      <td>0.243249</td>\n",
       "      <td>25.431195</td>\n",
       "      <td>25.165515</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>256636</td>\n",
       "      <td>-2.549521</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>-2.586470</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>-1.762666</td>\n",
       "      <td>0.346175</td>\n",
       "      <td>25.775117</td>\n",
       "      <td>25.734473</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      beta   beta_er     betaU  betaU_er     betaP  betaP_er  \\\n",
       "0     77910 -1.741502  0.024925 -2.354964  0.024662 -1.865693  0.279375   \n",
       "1     84518 -2.549521  0.009677 -2.586471  0.009640 -2.292437  0.296615   \n",
       "2     88612 -1.512836  0.026670 -2.365419  0.024517 -0.750239  0.753999   \n",
       "3     90354  0.294356  0.032415 -2.437742  0.020813 -2.293543  0.798312   \n",
       "4     94574 -2.314442  0.010609 -2.682976  0.009851 -2.201824  0.287684   \n",
       "..      ...       ...       ...       ...       ...       ...       ...   \n",
       "125  219026 -1.568423  0.026264 -2.304623  0.025132 -1.775671  0.240694   \n",
       "126  219038 -2.010785  0.010870 -2.645554  0.009039 -2.061982  0.385636   \n",
       "127  219057 -1.780938  0.027366 -2.344245  0.026270 -2.173327  0.390124   \n",
       "128  219195 -2.032286  0.021082 -2.273814  0.020722 -1.901890  0.243249   \n",
       "129  256636 -2.549521  0.009677 -2.586470  0.009640 -1.762666  0.346175   \n",
       "\n",
       "        bouwen    bouwenA       sion  \n",
       "0    25.520460  24.974901  25.098317  \n",
       "1    25.775118  25.734473        NaN  \n",
       "2    25.531961  24.837702        NaN  \n",
       "3    25.611516  23.753386        NaN  \n",
       "4    25.881274  25.475886        NaN  \n",
       "..         ...        ...        ...  \n",
       "125  25.465085  24.871054        NaN  \n",
       "126  25.840110  25.141863        NaN  \n",
       "127  25.508669  24.998563        NaN  \n",
       "128  25.431195  25.165515        NaN  \n",
       "129  25.775117  25.734473        NaN  \n",
       "\n",
       "[130 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sionx=[]\n",
    "for i in range(1):\n",
    "    potato=str(Montague['id'][i])\n",
    "#     potato=str(17189)\n",
    "    galaxy_fit = pd.read_csv(os.path.expanduser(path+'/'+potato+'.fit'),index_col=0,on_bad_lines='skip')\n",
    "    redshift =float(galaxy_fit.index[6].split()[-1])\n",
    "#     df = pd.read_csv(os.path.expanduser('~/Documents/FMIGM-BluminosityParams/'+potato+'-RF-lum-FMIGM'),index_col=0,on_bad_lines='skip')\n",
    "    df=pd.read_csv(os.path.expanduser(patho+potato+'-RF-lum'+name_B),index_col=0,on_bad_lines='skip')\n",
    "    pos = (df['L_nuU'] - df['L_nuU'].iloc[(df['nu']-c/1500e-10).abs().argsort()[0]]).abs().argsort()[0]\n",
    "    const = df['L_nuU'][pos]\n",
    "#     df\n",
    "    result=integral_above_cutoff(df['L_nuU'], df['nu'], const) #nu is in Hz df['L_nuU']*3.846*10**33\n",
    "    logresult=log10(result)\n",
    "    sionx.append(logresult)\n",
    "df2 = pd.concat([df1,pd.Series(sionx).rename('sion')],axis=1)\n",
    "# df2.to_csv('Bluminosity_'+str(name_B)+'test.csv',index=False)\n",
    "print('integration complete')\n",
    "print('How are you single')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "137f010f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JSN2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878de73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df2['betaP'],df2['sion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed55f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def integral_above_cutoff_2(L_nu, nu):\n",
    "#     cutoff_freq = c / (91.2e-9)\n",
    "#     mask = nu>cutoff_freq\n",
    "#     nu_above_cutoff = nu[mask]\n",
    "#     L_nu_above_cutoff = L_nu[mask]\n",
    "#     dnu = np.diff(nu_above_cutoff)\n",
    "# #     integrand_above_cutoff = integrand(nu_above_cutoff,L_nu_above_cutoff)\n",
    "#     integrand_above_cutoff = L_nu_above_cutoff[1:]\n",
    "# #     print(L_nu_above_cutoff[1:])\n",
    "#     integral = np.sum(dnu*integrand_above_cutoff)\n",
    "# #     integral = np.trapz(integrand_above_cutoff, nu_above_cutoff)\n",
    "#     return -integral\n",
    "\n",
    "# path = os.path.expanduser('~/Documents/ZFOURGE/')\n",
    "# patho = os.path.expanduser('~/Documents/ZFOURGEB/')\n",
    "# folder_name = os.path.basename(patho)  # Get the folder name \"anshuB\"\n",
    "# name_B = folder_name[:-1]\n",
    "# Montague = pd.read_csv(os.path.expanduser(path+'files/observations.dat'))\n",
    "# light=2.998*(10**18) #speed of light in Angstroms ~ A/s\n",
    "\n",
    "    \n",
    "# sionx=[]\n",
    "# constx=[]\n",
    "# for i in range(len(Montague)):\n",
    "#     potato=str(Montague['id'][i])\n",
    "# #     potato=str(17189)\n",
    "#     galaxy_fit = pd.read_csv(os.path.expanduser(path+'/'+potato+'.fit'),index_col=0,on_bad_lines='skip')\n",
    "#     redshift =float(galaxy_fit.index[6].split()[-1])\n",
    "# #     df = pd.read_csv(os.path.expanduser('~/Documents/FMIGM-BluminosityParams/'+potato+'-RF-lum-FMIGM'),index_col=0,on_bad_lines='skip')\n",
    "#     df=pd.read_csv(os.path.expanduser(patho+potato+'-RF-lum-ZFOURGE'),index_col=0,on_bad_lines='skip')\n",
    "# #     df=pd.read_csv(os.path.expanduser(patho+potato+'-RF-lum'+name_B),index_col=0,on_bad_lines='skip')\n",
    "#     pos = (df['L_nuU'] - df['L_nuU'].iloc[(df['nu']-c/1500e-10).abs().argsort()[0]]).abs().argsort()[0]\n",
    "#     const = df['L_nuU'][pos]\n",
    "#     constx.append(const)\n",
    "# #     df\n",
    "#     result=integral_above_cutoff_2(df['L_nuU'], df['nu']) #nu is in Hz df['L_nuU']*3.846*10**33\n",
    "#     logresult=result\n",
    "#     sionx.append(logresult)\n",
    "# df2 = pd.concat([Montague['id'],Montague['redshift'],pd.Series(sionx).rename('sion'),pd.Series(constx).rename('uv')],axis=1)\n",
    "# df2.to_csv('zLyCINT_'+name_B+'.csv',index=False)\n",
    "# print('integration complete')\n",
    "# print('How are you single')\n",
    "# df2\n",
    "\n",
    "# path = os.path.expanduser('~/Documents/JSN/')\n",
    "# patho = os.path.expanduser('~/Documents/JSNB/')\n",
    "# folder_name = os.path.basename(patho)  # Get the folder name \"anshuB\"\n",
    "# name_B = folder_name[:-1]\n",
    "# Montague = pd.read_csv(os.path.expanduser(path+'files/observations.dat'))\n",
    "\n",
    "# sionx=[]\n",
    "# constx=[]\n",
    "# for i in range(len(Montague)):\n",
    "#     potato=str(Montague['id'][i])\n",
    "# #     potato=str(17189)\n",
    "#     galaxy_fit = pd.read_csv(os.path.expanduser(path+'/'+potato+'.fit'),index_col=0,on_bad_lines='skip')\n",
    "#     redshift =float(galaxy_fit.index[6].split()[-1])\n",
    "# #     df = pd.read_csv(os.path.expanduser('~/Documents/FMIGM-BluminosityParams/'+potato+'-RF-lum-FMIGM'),index_col=0,on_bad_lines='skip')\n",
    "#     df=pd.read_csv(os.path.expanduser(patho+potato+'-RF-lum-JSN'),index_col=0,on_bad_lines='skip')\n",
    "#     pos = (df['L_nuU'] - df['L_nuU'].iloc[(df['nu']-c/1500e-10).abs().argsort()[0]]).abs().argsort()[0]\n",
    "#     const = df['L_nuU'][pos]\n",
    "#     constx.append(const)\n",
    "# #     df\n",
    "#     result=integral_above_cutoff_2(df['L_nuU'], df['nu']) #nu is in Hz df['L_nuU']*3.846*10**33\n",
    "#     logresult=result\n",
    "#     sionx.append(logresult)\n",
    "# df3 = pd.concat([Montague['id'],Montague['redshift'],pd.Series(sionx).rename('sion'),pd.Series(constx).rename('uv')],axis=1)\n",
    "# df3.to_csv('zLyCINT2_'+name_B+'.csv',index=False)\n",
    "# print('integration complete')\n",
    "# print('How are you still single')\n",
    "# df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd71dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=FancyPlot('redshift','lyc')\n",
    "ax.scatter(df2['redshift'],log10(df2['sion']))\n",
    "ax.scatter(df3['redshift'],log10(df3['sion']))\n",
    "\n",
    "fig,ax=FancyPlot('redshift','Normalization')\n",
    "ax.scatter(df2['redshift'],log10(df2['uv']))\n",
    "ax.scatter(df3['redshift'],log10(df3['uv']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434bea84",
   "metadata": {},
   "source": [
    "This is where the plotting starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22016082",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.expanduser('~/notebook/Laptop/')\n",
    "A = Table.read(os.path.expanduser(path+'Anshu-9150-Parameters.csv'), format='ascii')\n",
    "A=A.to_pandas()\n",
    "# # a = Table.read(os.path.expanduser(path+'anshu_EELGs_2-Parameters.csv'), format='ascii')\n",
    "# a = Table.read(os.path.expanduser(path+'anshu_EELGs_3-Parameters.csv'),format='ascii')\n",
    "# a=a.to_pandas()\n",
    "# AB = Table.read(os.path.expanduser(path+'Bluminosity_Anshu_control.csv'), format='ascii')\n",
    "# AB=AB.to_pandas()\n",
    "# ab = Table.read(os.path.expanduser(path+'Bluminosity_anshu_EELGs.csv'), format='ascii')\n",
    "# ab=ab.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aa49c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=FancyPlot(r'$M_{*}/M_\\odot$',r'sSFR$/yr^{-1}$')\n",
    "ax.scatter(log10(A['M(stars)']),log10(A['sSFR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581f621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=FancyPlot(r'$M_{*}/M_\\odot$',r'$M_{*}/M_\\odot$ removed')\n",
    "ax.scatter(log10(a['M(stars)']),log10(ac['M(stars)']),c='aquamarine',s=500,label='control')\n",
    "ax.plot(linspace(7,10,10),linspace(7,10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f207d33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = os.path.expanduser('~/notebook/Laptop/')\n",
    "ac = Table.read(os.path.expanduser(path+'anshu_EELGs_4-Parameters.csv'),format='ascii')\n",
    "ac=ac.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7814f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('Bluminosity_anshu_EELGs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89bbe30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mpl.rcParams.update({'font.size': 22})\n",
    "\n",
    "fig,ax=FancyPlot(r'$M_{*}/M_\\odot$',r'sSFR/$yr^{-1}$')\n",
    "ax.scatter(log10(A['M(stars)']),log10(A['sSFR']),c='aquamarine',s=500,label='control')\n",
    "ax.scatter(log10(a['M(stars)']),log10(a['sSFR']),c='dodgerblue',marker='*',s=500,label='EELGs')\n",
    "plt.legend()\n",
    "\n",
    "fig,ax=FancyPlot(r'$M_{*}/M_\\odot$',r'SFR/$M_\\odot yr^{-1}$')\n",
    "ax.scatter(log10(A['M(stars)']),log10(A['SFR']),c='aquamarine',s=500,label='control')\n",
    "ax.scatter(log10(a['M(stars)']),log10(a['SFR']),c='dodgerblue',marker='*',s=500,label='EELGs')\n",
    "plt.legend()\n",
    "\n",
    "fig,ax=FancyPlot(r'Photometric $\\beta$',r'$log_{10}(\\xi_{ion}$/Hz $erg^{-1})$')\n",
    "ax.errorbar(AB['betaP'],AB['sion'],xerr=AB['betaP_er'],markersize=20,fmt='o',\n",
    "               ecolor='aquamarine', alpha=1,zorder=1,c='aquamarine',linewidth=4,label='control')\n",
    "ax.errorbar(ab['betaP'],ab['sion'],xerr=ab['betaP_er'],markersize=20,fmt='*',\n",
    "               ecolor='dodgerblue', alpha=1,zorder=2,c='dodgerblue',linewidth=4,label='EELGs')\n",
    "# ax.set_ylim(24.4,25.6)\n",
    "# ax.set_xlim(-5,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad1f6c1",
   "metadata": {},
   "source": [
    "This is where I derive the slope and xi_ion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cafd95b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = os.path.expanduser('~/Documents/anshu/')\n",
    "\n",
    "Montague = pd.read_csv(os.path.expanduser(path+'files/observations.dat')) \n",
    "\n",
    "path2 = os.path.expanduser('~/Documents/')\n",
    "comp_ew=Table.read(os.path.expanduser(path2+'comp_ew.dat'),format='ascii')\n",
    "xy = comp_ew.to_pandas()\n",
    "xyz = xy[xy['col1']<100000]\n",
    "stuff = xyz.drop(['col3','col4'],axis=1)\n",
    "stuff.rename(columns={'col1':'id' ,'col2':'redshift'} ,inplace=True)\n",
    "\n",
    "\n",
    "# Montague2 = Montague.where(Montague['id'].isin(stuff['id'])).dropna()\n",
    "for Treesa in range(len(Montague)):\n",
    "#     potato=str(int(Montague2['id'].iloc[19]))\n",
    "    potato=str(Montague['id'][Treesa])\n",
    "#     potato=str(217157)#11999\n",
    "    galaxy_sed = pd.read_csv(os.path.expanduser(path+'/'+potato+'.sed'),index_col=None, header=None,on_bad_lines='skip', skiprows=10,delim_whitespace=True)\n",
    "    galaxy_sed.columns = ['A', 'B', 'C']\n",
    "    A=galaxy_sed['A']\n",
    "    B=galaxy_sed['B']\n",
    "    C=galaxy_sed['C']\n",
    "    galaxy_fit = pd.read_csv(os.path.expanduser(path+'/'+potato+'.fit'),index_col=0,on_bad_lines='skip')\n",
    "    galaxy_fit2 = pd.DataFrame(columns=['Full'])\n",
    "    Filters = pd.read_csv(os.path.expanduser(path+'/files/filters.dat'))\n",
    "    lambda_c =Filters['$\\lambda_c$']\n",
    "    galaxy_fit3 = pd.DataFrame(columns=[])\n",
    "    galaxy_fit_s = galaxy_fit.drop(galaxy_fit.index[[0,1,2,3,4,5,6,7,8,9,10,11,12,13]])\n",
    "\n",
    "    \n",
    "    \n",
    "    #SED FILE is in L_lambda/LoA^-1. A is log of the wavelength in angstroms\n",
    "    \n",
    "    redshift =float(galaxy_fit.index[6].split()[-1])\n",
    "    light=2.998*(10**18) #speed of light in Angstroms ~ A/s\n",
    "    lambda_cA = lambda_c*10000 #central wavelength in Angstroms\n",
    "    x=cosmo.luminosity_distance(redshift)\n",
    "    meters=x*3.0857*10**22 #Mpc to m\n",
    "    dist = meters.value\n",
    "    B = np.array(B)\n",
    "    A = np.array(A)\n",
    "    L_lambda = 10**B #L_0/Angstroms\n",
    "    lambd = 10**A #Angstroms\n",
    "    L_nu=L_lambda*lambd**2/light #L_0\n",
    "    f_nu = (L_nu*(3.826*10**26)*(1+redshift))/(4*pi*dist**2)\n",
    "#     f_nu = (L_nu*(3.826*10**26))/(4*pi*dist**2)\n",
    "    f_nu = f_nu/10**-26\n",
    "    # print(f_nu)\n",
    "\n",
    "    C = np.array(C)\n",
    "    L_lambda2=10**C\n",
    "    L_nu2=L_lambda2*lambd**2/light\n",
    "    f_nu2 =(L_nu2*(3.826*10**26)*(1+redshift))/(4*pi*dist**2)\n",
    "    f_nu2 = f_nu2/10**-26\n",
    "\n",
    "    f_lambda = light*f_nu/lambd**2\n",
    "    f_lambda2 = light*f_nu2/lambd**2\n",
    "    \n",
    "    \n",
    "  \n",
    "    ###################################################\n",
    "    for i in range(len(galaxy_fit)):\n",
    "        line = galaxy_fit.index[i].split(\" \")\n",
    "        while(\"\" in line):\n",
    "            line.remove(\"\")\n",
    "        if len(line) !=23: #14 23\n",
    "            continue\n",
    "        str_line = \" \".join(str(item) for item in line)\n",
    "        galaxy_fit2.loc[i]=str(str_line)\n",
    "\n",
    "\n",
    "    names = []\n",
    "    for i in range(len(Filters['Name'])):\n",
    "          names.append(Filters.iloc[i,0])\n",
    "    names\n",
    "    galaxy_fit2[names] = galaxy_fit2['Full'].str.split(\" \",expand=True,)\n",
    "    galaxy_fit2=galaxy_fit2.drop(['Full'],axis=1)\n",
    "    \n",
    "\n",
    "    test=Table.from_pandas(galaxy_fit2)\n",
    "    L_nu=[float(s) for s in test[0]] #First row.\n",
    "    L_nu_err=[float(s) for s in test[1]] #Second row\n",
    "    L_nu=np.array(L_nu) #Luminosity per unit Hz - L_o/s^-1 = L_o*s This is a flux unit but it's not Janskys. \n",
    "    L_nu_err=np.array(L_nu_err)\n",
    "\n",
    "    L_nu_err=L_nu_err#*(1+redshift)\n",
    "    lL_lambda_err=L_nu_err*light/lambda_cA\n",
    "\n",
    "\n",
    "    L_lambda=L_nu*light/(lambda_cA)**2 #L_o*s * A/s /A^2 = L_o/A\n",
    "    lL_lambda=L_lambda*lambda_cA #A *L_o/A =L_o\n",
    "\n",
    "    arr = np.array(A) #log(A) from SED file\n",
    "    arr2 = 10**(arr) #Angstroms (A)\n",
    "    wavelengths = arr2.tolist() #A\n",
    "    Qlog=log10(wavelengths) #log(A)\n",
    "    Atten = np.array(B) #log(L_o/A)\n",
    "    D = (10**Atten)*wavelengths #L_o/A *A = L_o\n",
    "\n",
    "    D=D.tolist()\n",
    "    # D = (10**Atten)*Q #L_o/A *A = L_o     #*10000) #Luminosity per unit lambda\n",
    "    Unatten = np.array(C)\n",
    "    E = (10**Unatten)*wavelengths  \n",
    "\n",
    "\n",
    "    E=E.tolist()     #*10000) #^\n",
    "    Atten_log=log10(D) #log(L_o)\n",
    "    Unatten_log=log10(E)\n",
    "    z=log10(lL_lambda) #log(L_o)\n",
    "    t=log10(lambda_cA) #log(A)\n",
    "\n",
    "\n",
    "    L_obs =[float(s) for s in test[2]]#Third Row\n",
    "    L_obs =np.array(L_obs)\n",
    "    Res = (L_nu - L_obs)/L_nu\n",
    "    for i in range(len(Res)):\n",
    "#         if log10(-Res[i])>5:\n",
    "#             Res[i]=nan\n",
    "        if L_nu[i] <0:\n",
    "            Res[i]=nan\n",
    "    plt.style.use('dark_background')\n",
    "    fig,ax1,ax2=StackedPlot('',r'log($\\lambda$ L$_\\lambda$ /L$_o$ )',r'log($\\lambda$/ \\AA)','')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_ylim(bottom=10**7, top=10**12)\n",
    "    ax1.set_xlim(left=10**3.4,right=10**5.1)\n",
    "#     ax1.rcParams['font.size'] = '18'\n",
    "    ax1.plot(10**Qlog,10**Atten_log/(1+redshift),label='Attenuated',c='deeppink')\n",
    "    ax1.plot(10**Qlog,10**Unatten_log/(1+redshift),label='Unattenuated',c='dodgerblue')\n",
    "    ax1.legend()\n",
    "#     ax1.scatter(t,z)#,label='*$\\lambda$')\n",
    "    ax1.errorbar(10**t,10**z,yerr=lL_lambda_err,fmt='o',c='aquamarine',ms=17)\n",
    "    ax1.errorbar(10**t.iloc[33:36],10**z.iloc[33:36], yerr=lL_lambda_err.iloc[33:36],fmt='o',markerfacecolor='red',markeredgecolor='k',ms=17)\n",
    "    ax1.axvline(x=(redshift*3000+3000),c='salmon')\n",
    "    ax1.axvline(x=(redshift*1300+1300),c='salmon')\n",
    "#     axs[1] = plt.axes([0,0,1,1])\n",
    "\n",
    "    ax1.annotate('z-'+str(redshift),xy=(10**4.8,10**9),size=25)\n",
    "    ax2.set_xlim(left=3.4,right=5.1)\n",
    "    \n",
    "    for i in range(len(Res)):\n",
    "        if Res[i]>1:\n",
    "            ax2.arrow(t[i],0,0,1,head_width=0.03, head_length=1, fc='aquamarine', ec='aquamarine')\n",
    "        if Res[i]<-1:\n",
    "            ax2.arrow(t[i],0,0,-1,head_width=0.03, head_length=1, fc='aquamarine', ec='aquamarine')\n",
    "    for i in range(len(Res)):\n",
    "        if abs(Res[i])>1:\n",
    "            Res[i]=nan\n",
    "    ax2.scatter(t,Res,label='Residuals')\n",
    "    ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da2e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357452e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
